import numpy as np
import scipy.stats as stats
import matplotlib.path as mpath
import matplotlib.patches as mpatches
from shapely.geometry import Point
from shapely.geometry.polygon import Polygon


def points_(region):
    """
    Receive vertices of the rectangular polygon.

    Parameters
    ----------
    region : shapely.geometry.polygon.Polygon
        The polygon representing the rectangle.

    Returns
    -------
    points : numpy.ndarray
        The vertices of the polygon.
    """
    corner = (region.bounds[0], region.bounds[1])
    width = region.bounds[2] - region.bounds[0]
    height = region.bounds[3] - region.bounds[1]
    rectangle = mpatches.Rectangle(corner, width, height, angle=0)
    points = rectangle.get_verts()

    return points


def contains(region, samples):
    """
    Receive indices of samples contained inside the close rectangle.

    Parameters
    ----------
    region : shapely.geometry.polygon.Polygon
        The polygon representing the rectangle.
    samples : numpy.ndarray
        The samples.

    Returns
    -------
    inside_indices : numpy.ndarray
        The indices of samples contained in the closed rectangle.
    """
    points = points_(region)
    polygon_path = mpath.Path(points, closed=True)
    mask = polygon_path.contains_points(samples)
    inside_indices = np.nonzero(mask)[0]

    return inside_indices


def make_poisson(intensity, region, seed=None):
    """
    Simulate random samples located in a rectangular region. The amount of samples is drawn from a poisson
    distribution with a rate of intensity * A(region).

    Parameters
    ----------
    intensity : float
        The expected intensity of samples per unit region measure.
    region : shapely.geometry.polygon.Polygon
        The polygon representing the rectangle.
    seed : numpy.random.BitGenerator, int or numpy.ndarray
        Seed of random number generation.

    Returns
    -------
    samples : numpy.ndarray
        The simulated samples.
    """
    rng = np.random.default_rng(seed)
    n_samples = rng.poisson(lam=intensity*region.area)
    corner = (region.bounds[0], region.bounds[1])
    width = region.bounds[2] - region.bounds[0]
    height = region.bounds[3] - region.bounds[1]
    new_samples = rng.random(size=(n_samples, 2))
    samples = (width, height) * new_samples + corner

    return samples


def limits(parent_intensities, parent_intensity, limit):
    """
    Receive a limit for each of parent_intensities, adjusted such that each product equals the product of the provided
    parent_intensity and limit.

    Parameters
    ----------
    parent_intensities : array-like
        The parent intensities whose limits shall be adjusted.
    parent_intensity : float
        The parent intensity whose limit is provided.
    limit : float
        The limit of the parent intensity.

    Returns
    -------
    all_limits : list
        A list of limits where each limit corresponds to an entry of parent_intensities.
    """
    all_limits = []
    for parent_int in parent_intensities:
        limit_ = np.sqrt(parent_intensity/parent_int * limit**2)
        all_limits.append(limit_)
    return all_limits


def make_dstorm(parent_intensity, lower_limit, upper_limit, cluster_mu, cluster_std, expansion_factor=6,
                min_points=0, clip=True, shuffle=True, seed=None):
    """
    Simulate samples distributed by complete spatial randomness (Poisson point process). These samples are
    the parent points. They are then used to produce offsprings normal distributed around the parent point.
    The amount of offsprings of each parent point is drawn from a geometric distribution.
    Parameters
    ----------
    parent_intensity : float
        The expected intensity of parent points per unit region measure.
    lower_limit : float
        Lower limit of x and y of the rectangular region.
    upper_limit : float
        Upper limit of x and y of the rectangular region.
    cluster_mu : int
        The mean of the geometric distribution of the offspring counts.
    cluster_std : float
        The standard deviation of the normal distribution with the parent points as mean.
    expansion_factor : float
        Factor by which the cluster_std is multiplied to set a distance by which the rectangular region is extended.
    min_points : int
        Defines the minimum x-value of the geometric distribution of the offspring counts.
    clip : bool
        If True, the result will be clipped to the non-extended rectangular region.
    shuffle : bool
        If True, the result is shuffled.
    seed : numpy.random.BitGenerator, int or numpy.ndarray
        Seed of random number generation.

    Returns
    -------
    samples : numpy.ndarray
        The offsprings generated by the parent points.
    labels : numpy.ndarray
        The labels of the offsprings. All offsprings originating from the same parent point share a unique label.
    parent_samples : numpy.ndarray
        The parent points.
    """
    rng = np.random.default_rng(seed)
    polygon = Polygon([(lower_limit, lower_limit), (lower_limit, upper_limit),
                       (upper_limit, upper_limit), (upper_limit, lower_limit)])

    # expand region
    expansion_distance = expansion_factor * np.max(cluster_std)
    polygon_expanded = polygon.buffer(expansion_distance)

    parent_samples = make_poisson(intensity=parent_intensity, region=polygon_expanded, seed=rng)
    n_cluster = len(parent_samples)

    n_offspring_list = rng.geometric(p=1 / (cluster_mu + 1 - min_points), size=n_cluster) - 1 + min_points
    cluster_std_ = np.full(shape=(n_cluster, 2), fill_value=cluster_std)
    samples = []
    labels = []
    for i, (parent, std, n_offspring) in enumerate(zip(parent_samples, cluster_std_, n_offspring_list)):
        offspring_samples = rng.normal(loc=parent, scale=std, size=(n_offspring, 2))
        samples.append(offspring_samples)
        labels += [i] * len(offspring_samples)

    samples = np.concatenate(samples) if len(samples) != 0 else np.array([])
    labels = np.array(labels)

    if clip is True:
        if len(samples) != 0:
            inside_indices = contains(polygon, samples)
            samples = samples[inside_indices]
            labels = labels[inside_indices]

    if shuffle:
        shuffled_indices = rng.permutation(len(samples))
        samples = samples[shuffled_indices]
        labels = labels[shuffled_indices]

    if len(samples) == 0:  # this is to convert empty arrays into arrays with shape (n_samples, n_features).
        samples = np.array([])
        samples = samples[:, np.newaxis]

    return samples, labels, parent_samples


def sim_dstorm(parent_intensity, lower_limit, upper_limit, cluster_mu, cluster_std, seed, min_samples):
    """
    Extends the function make_dstorm such that parent samples that were generated in the extended rectangular region
    are discarded. It also converts all labels, that occur less than min_samples times, into -1 (i.e. noise, many
    python implemented clustering algorithms use -1 as noise). Therefore, it generates a ground truth for potential
    clustering analysis.

    Parameters
    ----------
    parent_intensity : float
        The expected intensity of parent points per unit region measure.
    lower_limit : float
        Lower limit of x and y of the rectangular region.
    upper_limit : float
        Upper limit of x and y of the rectangular region.
    cluster_mu : int
        The mean of the geometric distribution of the offspring counts.
    cluster_std : float
        The standard deviation of the normal distribution with the parent points as mean.
    seed : numpy.random.BitGenerator, int or numpy.ndarray
        Seed of random number generation.
    min_samples : int
        Defines a minimum of occurrences of a unique label to be not converted to -1 (noise).

    Returns
    -------
    samples : numpy.ndarray
        The offsprings generated by the parent points.
    labels : numpy.ndarray
        The labels of the offsprings. If a label occurred less than min_samples times, it is -1.
    parent_samples_adj : numpy.ndarray
        The parent points, that are contained in the non-extended rectangular region.
    """
    samples, labels, parent_samples = make_dstorm(parent_intensity=parent_intensity, lower_limit=lower_limit,
                                                  upper_limit=upper_limit, cluster_mu=cluster_mu,
                                                  cluster_std=cluster_std, clip=True, seed=seed)
    polygon = Polygon([(lower_limit, lower_limit), (lower_limit, upper_limit),
                       (upper_limit, upper_limit), (upper_limit, lower_limit)])
    parent_samples_adj = []
    for i, parent_sample in enumerate(parent_samples):
        point = Point(parent_sample)
        if np.count_nonzero(labels == i) > min_samples - 1:
            parent_samples_adj.append(parent_sample)
        elif polygon.contains(point):
            parent_samples_adj.append(parent_sample)
            labels[labels == i] = -1
        else:
            labels[labels == i] = -1
    parent_samples_adj = np.array(parent_samples_adj)

    return samples, labels, parent_samples_adj


def make_random_walk(parent_intensity, lower_limit, upper_limit, cluster_mu, cluster_std, step_factor, n_steps,
                     min_range, expansion_factor=6, min_points=0, clip=True, shuffle=True, seed=None):
    """
    Simulate samples distributed by complete spatial randomness (Poisson point process). These samples are
    the parent points. They then perform a random walk for n_steps steps of euclidean distance step_factor.
    After each step, the euclidean distance of all parent points to each other is calculated. If the distance
    is below min_range, parents will stick together.
    They are then used to produce offsprings normal distributed around the parent point.
    The amount of offsprings of each parent point is drawn from a geometric distribution.

    Parameters
    ----------
    parent_intensity : float
        The expected intensity of parent points per unit region measure.
    lower_limit : float
        Lower limit of x and y of the rectangular region.
    upper_limit : float
        Upper limit of x and y of the rectangular region.
    cluster_mu : int
        The mean of the geometric distribution of the offspring counts.
    cluster_std : float
        The standard deviation of the normal distribution with the parent points as mean.
    step_factor : float
        Euclidean distance travelled by one step of the random walk.
    n_steps : int
        Total steps of the random walk.
    min_range : float
        Minimum euclidean distance of 2 parent points to stick together.
    expansion_factor : float
        Factor by which the cluster_std is multiplied to set a distance by which the rectangular region is extended.
    min_points : int
        Defines the minimum x-value of the geometric distribution of the offspring counts.
    clip : bool
        If True, the result will be clipped to the non-extended rectangular region.
    shuffle : bool
        If True, the result is shuffled.
    seed : numpy.random.BitGenerator, int or numpy.ndarray
        Seed of random number generation.

    Returns
    -------
    samples : numpy.ndarray
        The offsprings generated by the parent points.
    labels : numpy.ndarray
        The labels of the offsprings. All offsprings originating from the same parent point share a unique label.
    parent_samples : numpy.ndarray
        The parent points.
    clustered_parents : list
        Arrays for each parent point with all their sticking partners.
    """
    rng = np.random.default_rng(seed)
    polygon = Polygon([(lower_limit, lower_limit), (lower_limit, upper_limit),
                       (upper_limit, upper_limit), (upper_limit, lower_limit)])

    expansion_distance = expansion_factor * np.max(cluster_std)
    polygon_expanded = polygon.buffer(expansion_distance)

    low_lim_exp = lower_limit - expansion_distance
    up_lim_exp = upper_limit + expansion_distance

    parent_samples = make_poisson(intensity=parent_intensity, region=polygon_expanded, seed=rng)
    n_cluster = len(parent_samples)

    phi = np.arange(0, 360.1, 0.1)
    x = np.cos(phi)
    y = np.sin(phi)
    step_set = np.stack((x, y), axis=1)

    locations = parent_samples

    clustered_parents = []
    for j in range(n_steps + 1):
        step = np.array(rng.choice(step_set * step_factor, size=n_cluster, replace=True))
        for i in range(n_cluster):
            origin = locations[i]
            origin_resize = np.reshape(origin, (-1, 2))
            origin_resize = np.repeat(origin_resize, n_cluster, axis=0)
            eucl = np.linalg.norm(origin_resize - locations, axis=1)
            h, = np.where(eucl < min_range)
            if j == n_steps:
                clustered_parents.append(h)
            else:
                step[h] = step[i]
                new_location = origin + step[i]
                if new_location[0] > up_lim_exp:
                    new_location[0] = low_lim_exp - (up_lim_exp - new_location[0])
                elif new_location[0] < low_lim_exp:
                    new_location[0] = up_lim_exp - (low_lim_exp - new_location[0])
                if new_location[1] > up_lim_exp:
                    new_location[1] = low_lim_exp - (up_lim_exp - new_location[1])
                elif new_location[1] < low_lim_exp:
                    new_location[1] = up_lim_exp - (low_lim_exp - new_location[1])
                locations[i] = new_location

    n_offspring_list = rng.geometric(p=1 / (cluster_mu + 1 - min_points), size=n_cluster) - 1 + min_points
    cluster_std_ = np.full(shape=(n_cluster, 2), fill_value=cluster_std)

    samples = []
    labels = []
    for i, (parent, std, n_offspring) in enumerate(zip(locations, cluster_std_, n_offspring_list)):
        offspring_samples = rng.normal(loc=parent, scale=std, size=(n_offspring, 2))
        samples.append(offspring_samples)
        labels += [i] * len(offspring_samples)

    samples = np.concatenate(samples) if len(samples) != 0 else np.array([])
    labels = np.array(labels)

    if clip is True:
        if len(samples) != 0:
            inside_indices = contains(polygon, samples)
            samples = samples[inside_indices]
            labels = labels[inside_indices]

    if shuffle:
        shuffled_indices = rng.permutation(len(samples))
        samples = samples[shuffled_indices]
        labels = labels[shuffled_indices]

    if len(samples) == 0:  # this is to convert empty arrays into arrays with shape (n_samples, n_features).
        samples = np.array([])
        samples = samples[:, np.newaxis]

    return samples, labels, parent_samples, clustered_parents


def sim_random_walk(parent_intensity, lower_limit, upper_limit, cluster_mu, cluster_std, seed, min_samples,
                    step_factor, n_steps, min_range):
    """
    Extends the function make_random_walk such that parent samples that were generated in the extended rectangular
    region are discarded. All labels of samples that originate from parents sticking together are unified (new labels,
    also contains unaffected labels). It then converts all new labels, that occur less than min_samples times, into -1
    (i.e. noise, many python implemented clustering algorithms use -1 as noise). The amount of parents behind each kept
    new label is also stored.

    Parameters
    ----------
    parent_intensity : float
        The expected intensity of parent points per unit region measure.
    lower_limit : float
        Lower limit of x and y of the rectangular region.
    upper_limit : float
        Upper limit of x and y of the rectangular region.
    cluster_mu : int
        The mean of the geometric distribution of the offspring counts.
    cluster_std : float
        The standard deviation of the normal distribution with the parent points as mean.
    step_factor : float
        Euclidean distance travelled by one step of the random walk.
    n_steps : int
        Total steps of the random walk.
    min_range : float
        Minimum euclidean distance of 2 parent points to stick together.
    seed : numpy.random.BitGenerator, int or numpy.ndarray
        Seed of random number generation.
    min_samples : int
        Defines a minimum of occurrences of a unique (new) label to be not converted to -1 (noise).

    Returns
    -------
    samples : numpy.ndarray
        The offsprings generated by the parent points.
    labels : numpy.ndarray
        The new labels of the offsprings. If a new label occurred less than min_samples times, it is -1.
    original_size : numpy.ndarray
        The original amount of labels a new label is representing.
    parent_samples_adj : numpy.ndarray
        The parent points, that are contained in the non-extended rectangular region.
    """
    samples, labels, parent_samples, \
        clustered_parents = make_random_walk(parent_intensity=parent_intensity, lower_limit=lower_limit,
                                             upper_limit=upper_limit, cluster_mu=cluster_mu, cluster_std=cluster_std,
                                             seed=seed, n_steps=n_steps, step_factor=step_factor, min_range=min_range)
    new_labels = np.copy(labels)

    for clustered_parents_ in clustered_parents:
        right_label = clustered_parents_[0]
        wrong_label = clustered_parents_[1:]
        wrong_indices = np.in1d(new_labels, wrong_label).nonzero()  # nonzero on boolean values equals True
        new_labels[wrong_indices] = right_label

    polygon = Polygon([(lower_limit, lower_limit), (lower_limit, upper_limit),
                       (upper_limit, upper_limit), (upper_limit, lower_limit)])
    parent_samples_adj = []
    for i, parent_sample in enumerate(parent_samples):
        point = Point(parent_sample)
        indices = np.where(labels == i)
        new_label = np.unique(new_labels[indices])
        if np.count_nonzero(new_labels == new_label) > min_samples - 1:
            parent_samples_adj.append(parent_sample)
        elif polygon.contains(point):
            parent_samples_adj.append(parent_sample)
            new_labels[indices] = -1
        else:
            new_labels[indices] = -1
    parent_samples_adj = np.array(parent_samples_adj)

    uniques = np.unique(new_labels)
    uniques = np.delete(uniques, np.where(uniques == -1))
    original_size = []
    for i in uniques:
        indices = np.where(new_labels == i)
        corres_labels = labels[indices]
        cor_labl_len = len(np.unique(corres_labels))
        original_size.append(cor_labl_len)
    original_size = np.array(original_size)

    return samples, new_labels, original_size, parent_samples_adj


def make_clusters(parent_intensity, lower_limit, upper_limit, cluster_mu, cluster_std, ratio, radius, replace_mu, mode,
                  expansion_factor=6, min_points=0, clip=True, shuffle=True, seed=None):
    """
    Simulate samples distributed by complete spatial randomness (Poisson point process). These samples are the parent
    points. A certain amount (ratio) of them is selected and replaced by new parent points. The amount of new parents
    is drawn from a geometric distribution with mean replace_mu. New parents are then randomly distributed around the
    original parents coordinates within a circular area of radius, if mode is "poisson". If mode is "normal", new
    parents are normal distributed around the original parent with the standard deviation radius.
    The non-selected parents and the new parents are then used to produce offsprings normal distributed around the
    parent point. The amount of offsprings of each parent point is drawn from a geometric distribution.

    Parameters
    ----------
    parent_intensity : float
        The expected intensity of parent points per unit region measure.
    lower_limit : float
        Lower limit of x and y of the rectangular region.
    upper_limit : float
        Upper limit of x and y of the rectangular region.
    cluster_mu : int
        The mean of the geometric distribution of the offspring counts.
    cluster_std : float
        The standard deviation of the normal distribution with the parent points as mean.
    ratio : float
        Number between 0 and 1 to determine the portion of replaced parent points.
    radius : float
        Radius of circular area in case mode is "poisson" or standard deviation in case mode is "normal".
    replace_mu : int
        The mean of the geometric distribution of the new parent counts.
    mode : str
        One of "poisson", "normal".
    expansion_factor : float
        Factor by which the cluster_std is multiplied to set a distance by which the rectangular region is extended.
    min_points : int
        Defines the minimum x-value of the geometric distribution of the offspring counts.
    clip : bool
        If True, the result will be clipped to the non-extended rectangular region.
    shuffle : bool
        If True, the result is shuffled.
    seed : numpy.random.BitGenerator, int or numpy.ndarray
        Seed of random number generation.

    Returns
    -------
    samples : numpy.ndarray
        The offsprings generated by the parent points.
    labels : numpy.ndarray
        The labels of the offsprings. All offsprings originating from the same parent point share a unique label.
    parent_samples : numpy.ndarray
        The parent points.
    clustered_parents : list
        Arrays for each selected original parent point containing the indices of parent_samples representing their
        replacements.
    """
    rng = np.random.default_rng(seed)
    polygon = Polygon([(lower_limit, lower_limit), (lower_limit, upper_limit),
                       (upper_limit, upper_limit), (upper_limit, lower_limit)])

    expansion_distance = expansion_factor * np.max(cluster_std)
    polygon_expanded = polygon.buffer(expansion_distance)

    parent_samples = make_poisson(intensity=parent_intensity, region=polygon_expanded, seed=rng)
    selected_parents = np.array(rng.choice(parent_samples, size=int(len(parent_samples) * ratio),
                                           replace=False))
    indices = np.unique(np.where(np.isin(parent_samples, selected_parents))[0])
    parent_samples = np.delete(parent_samples, indices, axis=0)
    n_parent_replace = rng.geometric(p=1 / (replace_mu + 1), size=len(selected_parents)) - 1
    clustered_parents = []
    for i, (parent, replace) in enumerate(zip(selected_parents, n_parent_replace)):
        if mode == "poisson":
            point = Point(parent)
            circle = point.buffer(radius)
            intensity = replace / circle.area
            new_parents = make_poisson(intensity=intensity, region=circle, seed=rng)
        elif mode == "normal":
            new_parents = rng.normal(loc=parent, scale=radius, size=(replace, 2))
        else:
            new_parents = None
        parent_samples = np.concatenate((parent_samples, new_parents))
        clustered_parents_ = np.unique(np.where(np.isin(parent_samples, new_parents))[0])
        clustered_parents.append(clustered_parents_)
    n_cluster = len(parent_samples)

    n_offspring_list = rng.geometric(p=1 / (cluster_mu + 1 - min_points), size=n_cluster) - 1 + min_points
    cluster_std_ = np.full(shape=(n_cluster, 2), fill_value=cluster_std)
    samples = []
    labels = []
    for i, (parent, std, n_offspring) in enumerate(zip(parent_samples, cluster_std_, n_offspring_list)):
        offspring_samples = rng.normal(loc=parent, scale=std, size=(n_offspring, 2))
        samples.append(offspring_samples)
        labels += [i] * len(offspring_samples)

    samples = np.concatenate(samples) if len(samples) != 0 else np.array([])
    labels = np.array(labels)

    if clip is True:
        if len(samples) != 0:
            inside_indices = contains(polygon, samples)
            samples = samples[inside_indices]
            labels = labels[inside_indices]

    if shuffle:
        shuffled_indices = rng.permutation(len(samples))
        samples = samples[shuffled_indices]
        labels = labels[shuffled_indices]

    if len(samples) == 0:  # this is to convert empty arrays into arrays with shape (n_samples, n_features).
        samples = np.array([])
        samples = samples[:, np.newaxis]

    return samples, labels, parent_samples, clustered_parents


def sim_clusters(parent_intensity, lower_limit, upper_limit, cluster_mu, cluster_std, ratio, radius,
                 replace_mu, mode, seed, min_samples):
    """
    Extends the function make_clusters such that parent samples that were generated in the extended rectangular
    region are discarded. All labels of samples that originate from parents replacing one original parent are unified
    (new labels, also contains unaffected labels). It then converts all new labels, that occur less than min_samples
    times, into -1 (i.e. noise, many python implemented clustering algorithms use -1 as noise). The amount of parents
    behind each kept new label is also stored.

    Parameters
    ----------
    parent_intensity : float
        The expected intensity of parent points per unit region measure.
    lower_limit : float
        Lower limit of x and y of the rectangular region.
    upper_limit : float
        Upper limit of x and y of the rectangular region.
    cluster_mu : int
        The mean of the geometric distribution of the offspring counts.
    cluster_std : float
        The standard deviation of the normal distribution with the parent points as mean.
    ratio : float
        Number between 0 and 1 to determine the portion of replaced parent points.
    radius : float
        Radius of circular area in case mode is "poisson" or standard deviation in case mode is "normal".
    replace_mu : int
        The mean of the geometric distribution of the new parent counts.
    mode : str
        One of "poisson", "normal".
    seed : numpy.random.BitGenerator, int or numpy.ndarray
        Seed of random number generation.
    min_samples : int
        Defines a minimum of occurrences of a unique (new) label to be not converted to -1 (noise).

    Returns
    -------
    samples : numpy.ndarray
        The offsprings generated by the parent points.
    labels : numpy.ndarray
        The new labels of the offsprings. If a new label occurred less than min_samples times, it is -1.
    original_size : numpy.ndarray
        The original amount of labels a new label is representing.
    parent_samples_adj : numpy.ndarray
        The parent points, that are contained in the non-extended rectangular region.
    """
    samples, labels, parent_samples, \
        clustered_parents = make_clusters(parent_intensity=parent_intensity, lower_limit=lower_limit,
                                          upper_limit=upper_limit, cluster_mu=cluster_mu, cluster_std=cluster_std,
                                          seed=seed, replace_mu=replace_mu, mode=mode, ratio=ratio, radius=radius)
    new_labels = np.copy(labels)

    for clustered_parents_ in clustered_parents:
        if len(clustered_parents_) > 0:
            right_label = clustered_parents_[0]
            wrong_label = clustered_parents_[1:]
            wrong_indices = np.in1d(new_labels, wrong_label).nonzero()  # nonzero on boolean values equals True
            new_labels[wrong_indices] = right_label

    polygon = Polygon([(lower_limit, lower_limit), (lower_limit, upper_limit),
                       (upper_limit, upper_limit), (upper_limit, lower_limit)])
    parent_samples_adj = []
    for i, parent_sample in enumerate(parent_samples):
        point = Point(parent_sample)
        indices = np.where(labels == i)
        new_label = np.unique(new_labels[indices])
        if np.count_nonzero(new_labels == new_label) > min_samples - 1:
            parent_samples_adj.append(parent_sample)
        elif polygon.contains(point):
            parent_samples_adj.append(parent_sample)
            new_labels[indices] = -1
        else:
            new_labels[indices] = -1
    parent_samples_adj = np.array(parent_samples_adj)

    uniques = np.unique(new_labels)
    uniques = np.delete(uniques, np.where(uniques == -1))
    original_size = []
    for i in uniques:
        indices = np.where(new_labels == i)
        corres_labels = labels[indices]
        cor_labl_len = len(np.unique(corres_labels))
        original_size.append(cor_labl_len)
    original_size = np.array(original_size)

    return samples, new_labels, original_size, parent_samples_adj


######################################################################################################################
######################################################################################################################
def make_std_vary(parent_intensity, lower_limit, upper_limit, cluster_mu, intensity_mean, intensity_min, psf_sigma,
                  factor, distribution, clip=True, shuffle=True, min_points=0, expansion_factor=6, seed=None):
    rng = np.random.default_rng(seed)
    polygon = Polygon([(lower_limit, lower_limit), (lower_limit, upper_limit),
                       (upper_limit, upper_limit), (upper_limit, lower_limit)])

    cluster_std_max = psf_sigma/np.sqrt(intensity_min)
    expansion_distance = expansion_factor * cluster_std_max
    polygon_expanded = polygon.buffer(expansion_distance)

    parent_samples = make_poisson(intensity=parent_intensity, region=polygon_expanded, seed=rng)
    n_cluster = len(parent_samples)
    n_offspring_list = rng.geometric(p=1 / (cluster_mu + 1 - min_points), size=n_cluster) - 1 + min_points

    if distribution == "geometric":
        intensities = np.array(rng.geometric(p=1 / (intensity_mean + 1), size=100000000))
        intensities = intensities[intensities > intensity_min - 1]
        intensities_ = [rng.choice(intensities, size=n) for n in n_offspring_list]
    elif distribution == "gamma":
        intensities = stats.gamma.rvs(a=1, loc=intensity_min+1, scale=intensity_mean, size=100000000)
        intensities_ = [rng.choice(intensities, size=n) for n in n_offspring_list]
    else:
        intensities_ = None

    cluster_stds = [1/(np.sqrt(factor*np.array(intensities__))) * psf_sigma for intensities__ in intensities_]
    mean_cluster_std = np.mean(np.concatenate(cluster_stds))
    samples = []
    labels = []
    for i, (parent, std, n_offspring) in enumerate(zip(parent_samples, cluster_stds, n_offspring_list)):
        offspring_samples = [rng.normal(loc=parent, scale=std_, size=(n_offspring, 2)) for std_ in
                             std]
        if len(offspring_samples) != 0:
            offspring_samples = np.vstack(offspring_samples)
        else:
            offspring_samples = np.empty((0, 2))
        samples.append(offspring_samples)
        labels += [i] * len(offspring_samples)

    samples = np.concatenate(samples) if len(samples) != 0 else np.array([])
    labels = np.array(labels)

    if clip is True:
        if len(samples) != 0:
            inside_indices = contains(polygon, samples)
            samples = samples[inside_indices]
            labels = labels[inside_indices]

    if shuffle:
        shuffled_indices = rng.permutation(len(samples))
        samples = samples[shuffled_indices]
        labels = labels[shuffled_indices]

    if len(samples) == 0:  # this is to convert empty arrays into arrays with shape (n_samples, n_features).
        samples = np.array([])
        samples = samples[:, np.newaxis]

    return samples, labels, parent_samples, mean_cluster_std, cluster_stds, intensities_


def sim_std_vary(parent_intensity, lower_limit, upper_limit, cluster_mu, intensity_mean, intensity_min, psf_sigma,
                 factor, distribution, seed, min_samples):
    samples, labels, parent_samples, mean_cluster_std, cluster_stds, \
        intensities_ = make_std_vary(parent_intensity=parent_intensity, lower_limit=lower_limit,
                                     upper_limit=upper_limit, cluster_mu=cluster_mu, intensity_mean=intensity_mean,
                                     intensity_min=intensity_min, psf_sigma=psf_sigma, factor=factor,
                                     distribution=distribution, seed=seed)
    polygon = Polygon([(lower_limit, lower_limit), (lower_limit, upper_limit),
                       (upper_limit, upper_limit), (upper_limit, lower_limit)])
    all_cluster_centers_adjusted = []
    for i in range(len(parent_samples)):
        point = Point(parent_samples[i])
        if np.count_nonzero(labels == i) > min_samples - 1:
            all_cluster_centers_adjusted.append(parent_samples[i])
        elif polygon.contains(point):
            all_cluster_centers_adjusted.append(parent_samples[i])
            labels[labels == i] = -1
        else:
            labels[labels == i] = -1

    return samples, labels, parent_samples, mean_cluster_std, cluster_stds, intensities_, all_cluster_centers_adjusted
